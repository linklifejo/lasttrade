import time
import sqlite3
import json
import pandas as pd
from database import DB_FILE
from logger import logger

def analyze_signals():
    """ê¸°ì¡´ ë¶„ì„ ë¡œì§ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    report = get_analysis_report()
    print(report)
    return report

def get_analysis_report():
    """ë¶„ì„ ì„±ê³¼ ìš”ì•½ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    conn = sqlite3.connect(DB_FILE)
    query = '''
    SELECT 
        s.id, s.timestamp, s.code, s.factors_json, 
        r.interval_1m_change, r.interval_5m_change, r.max_drawdown, r.max_profit
    FROM signal_snapshots s
    JOIN response_metrics r ON s.id = r.signal_id
    '''
    try:
        df = pd.read_sql_query(query, conn)
    except Exception as e:
        return f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}"
    finally:
        conn.close()
    
    if df.empty:
        return "âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
    
    # 2. JSON í˜•íƒœì˜ íŒ©í„°ë“¤ì„ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¥
    factors_df = df['factors_json'].apply(lambda x: pd.Series(json.loads(x)))
    df = pd.concat([df.drop('factors_json', axis=1), factors_df], axis=1)
    
    report = []
    report.append(f"ğŸ“Š [LASTTRADE ìˆ˜í•™ì  ì—”ì§„ ì‹¬í™” ë¶„ì„ ë¦¬í¬íŠ¸]")
    report.append(f"âœ… ì´ ë¶„ì„ í‘œë³¸: {len(df)}ê±´")
    report.append(f"ğŸ“¡ [ëŒ€ì›ì¹™] RSI í•„í„°ë§ë³´ë‹¤ WATER ì „ëµ(í‰ë‹¨ê°€/ìˆ˜ì—´) ê´€ì ì—ì„œ ì„±ê³¼ ë¶„ì„\n")
    
    # --- RSI_1m ë¶„ì„ ---
    df['rsi_bin'] = pd.cut(df['rsi_1m'], bins=range(0, 105, 10))
    rsi_stats = df.groupby('rsi_bin')['interval_5m_change'].agg(['count', 'mean']).rename(columns={'mean': 'avg_profit'})
    rsi_stats['win_rate'] = df.groupby('rsi_bin')['interval_5m_change'].apply(lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0)
    
    report.append("[1. RSI 1m êµ¬ê°„ë³„ ì„±ê³¼]")
    for idx, row in rsi_stats.dropna().iterrows():
        if row['count'] > 0:
            report.append(f" â€¢ {idx}: {int(row['count']):3d}ê±´ | ìŠ¹ë¥  {row['win_rate']*100:4.1f}% | ìˆ˜ìµ {row['avg_profit']:5.2f}%")
    
    # --- RSI Diff (1m - 3m) ë¶„ì„ ---
    if 'rsi_diff' in df.columns:
        df['diff_bin'] = pd.cut(df['rsi_diff'], bins=[-100, -5, -2, 0, 2, 5, 100])
        diff_stats = df.groupby('diff_bin')['interval_5m_change'].agg(['count', 'mean']).rename(columns={'mean': 'avg_profit'})
        diff_stats['win_rate'] = df.groupby('diff_bin')['interval_5m_change'].apply(lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0)
        
        report.append("\n[2. RSI Difference (1m-3m) ì„±ê³¼]")
        for idx, row in diff_stats.dropna().iterrows():
            if row['count'] > 0:
                report.append(f" â€¢ {idx}: {int(row['count']):3d}ê±´ | ìŠ¹ë¥  {row['win_rate']*100:4.1f}% | ìˆ˜ìµ {row['avg_profit']:5.2f}%")

    # 4. ê²°í•© ìµœì  ì¡°í•© ì¶”ì²œ
    report.append(f"\nğŸ’¡ [ì—”ì§„ ìµœì í™” ì œì–¸]")
    best_rsi = rsi_stats[rsi_stats['count'] >= 3]['win_rate'].idxmax() if not rsi_stats[rsi_stats['count'] >= 3].empty else "N/A"
    report.append(f" - ìµœê³  ìŠ¹ë¥  RSI êµ¬ê°„: {best_rsi}")
    
    return "\n".join(report)

_cache_data = None
_last_cache_time = 0

def update_cache():
    global _cache_data, _last_cache_time
    try:
        conn = sqlite3.connect(DB_FILE)
        query = '''
        SELECT s.factors_json, r.interval_5m_change
        FROM signal_snapshots s
        JOIN response_metrics r ON s.id = r.signal_id
        '''
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if not df.empty:
            factors_df = df['factors_json'].apply(lambda x: pd.Series(json.loads(x)))
            _cache_data = pd.concat([df.drop('factors_json', axis=1), factors_df], axis=1)
            _last_cache_time = time.time()
            logger.info(f"ğŸ”„ [LASTTRADE Math] {len(_cache_data)}ê±´ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ì‹ ë² ì´ìŠ¤(ëŒ€ì›ì¹™ ê¸°ë°˜) ê°±ì‹  ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ì§€ì‹ ë² ì´ìŠ¤ ê°±ì‹  ì‹¤íŒ¨: {e}")

def get_win_probability(rsi_1m, rsi_diff=None):
    """
    RSIì™€ RSI ì°¨ì´ë¥¼ ê²°í•©í•˜ì—¬ ì˜ˆìƒ ìŠ¹ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    global _cache_data, _last_cache_time
    
    # 30ë¶„ë§ˆë‹¤ ìºì‹œ ê°±ì‹ 
    if _cache_data is None or (time.time() - _last_cache_time > 1800):
        update_cache()
    
    if _cache_data is None or _cache_data.empty:
        return 0.5, 0 # ë°ì´í„° ì—†ìœ¼ë©´ 50%
        
    # ê¸°ë³¸ê°’ ì„¤ì •
    base_prob = 0.5
    total_count = 0
    
    try:
        # 1. RSI ê¸°ë°˜ í™•ë¥  í•„í„°ë§
        rsi_margin = 5
        rsi_group = _cache_data[(_cache_data['rsi_1m'] >= rsi_1m - rsi_margin) & (_cache_data['rsi_1m'] <= rsi_1m + rsi_margin)]
        
        if not rsi_group.empty:
            rsi_prob = (rsi_group['interval_5m_change'] > 0).sum() / len(rsi_group)
            total_count = len(rsi_group)
            
            # 2. RSI Diff ë³´ì • (ìˆì„ ê²½ìš°)
            if rsi_diff is not None and 'rsi_diff' in rsi_group.columns:
                diff_margin = 2
                diff_group = rsi_group[(rsi_group['rsi_diff'] >= rsi_diff - diff_margin) & (rsi_group['rsi_diff'] <= rsi_diff + diff_margin)]
                if len(diff_group) >= 3:
                    diff_prob = (diff_group['interval_5m_change'] > 0).sum() / len(diff_group)
                    # RSI í™•ë¥ ê³¼ Diff í™•ë¥ ì˜ ê°€ì¤‘ í‰ê· 
                    base_prob = (rsi_prob * 0.4) + (diff_prob * 0.6)
                    total_count = len(diff_group)
                else:
                    base_prob = rsi_prob
            else:
                base_prob = rsi_prob
                
    except Exception as e:
        logger.error(f"ìŠ¹ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        
    return base_prob, total_count

if __name__ == "__main__":
    analyze_signals()
