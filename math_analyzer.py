import time
import sqlite3
import json
import pandas as pd
import re
from database import DB_FILE
from logger import logger

def analyze_signals():
    """ê¸°ì¡´ ë¶„ì„ ë¡œì§ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    report = get_analysis_report()
    print(report)
    return report

def get_analysis_report():
    """LASTTRADE ì›ì¹™ ê¸°ë°˜ ì„±ê³¼ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    conn = sqlite3.connect(DB_FILE)
    
    # 1. ì‹œê·¸ë„ ë°ì´í„° (RSI ë“±)
    signal_query = '''
    SELECT 
        s.id, s.timestamp, s.code, s.factors_json, 
        r.interval_1m_change, r.interval_5m_change, r.max_drawdown, r.max_profit
    FROM signal_snapshots s
    JOIN response_metrics r ON s.id = r.signal_id
    '''
    
    # 2. ì‹¤ì œ ë§¤ë§¤ ë°ì´í„° (WATER ë‹¨ê³„ ë¶„ì„ìš©)
    trade_query = 'SELECT * FROM trades WHERE type = "SELL" OR type = "sell"'
    
    try:
        df_sig = pd.read_sql_query(signal_query, conn)
        df_trades = pd.read_sql_query(trade_query, conn)
    except Exception as e:
        return f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}"
    finally:
        conn.close()
    
    report = []
    report.append(f"ðŸ“Š [LASTTRADE ìˆ˜í•™ì  ì—”ì§„ ì›ì¹™ ë¶„ì„ ë¦¬í¬íŠ¸]")
    
    # --- [ì„¹ì…˜ 1. WATER ì „ëžµ ë‹¨ê³„ë³„ ì„±ê³¼] ---
    report.append(f"\nðŸŒŠ [1. WATER ì „ëžµ (ë¬¼íƒ€ê¸°) íš¨ìœ¨ ë¶„ì„]")
    if not df_trades.empty:
        # reasonì—ì„œ Step ì •ë³´ ì¶”ì¶œ (ì˜ˆ: "WATER_STEP_2" -> 2)
        def extract_step(reason):
            if not reason: return 1
            match = re.search(r'STEP_(\d+)', str(reason))
            return int(match.group(1)) if match else 1
        
        # ì‹¤ì œë¡œëŠ” ë§¤ë„ ì‹œì ì˜ reasonì—ëŠ” ë§¤ìˆ˜ ë‹¨ê³„ê°€ ì—†ì„ ìˆ˜ë„ ìžˆìœ¼ë¯€ë¡œ 
        # ë§¤ìˆ˜ ê¸°ë¡ì„ ì°¾ì•„ í•´ë‹¹ ì¢…ëª©ì˜ ìµœëŒ€ ë‹¨ê³„ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì •í™•í•¨
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ memo/reasonì— ê¸°ë¡ëœ ê°’ì„ ìš°ì„  ì‚¬ìš©
        df_trades['step'] = df_trades['reason'].apply(extract_step)
        
        step_stats = df_trades.groupby('step')['profit_rate'].agg(['count', 'mean']).rename(columns={'mean': 'avg_profit'})
        step_stats['win_rate'] = df_trades.groupby('step')['profit_rate'].apply(lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0)
        
        for step, row in step_stats.iterrows():
            report.append(f" â€¢ {int(step)}ë‹¨ê³„ íƒˆì¶œ: {int(row['count']):3d}ê±´ | ìŠ¹ë¥  {row['win_rate']*100:4.1f}% | í‰ê· ìˆ˜ìµ {row['avg_profit']:5.2f}%")
        
        if len(step_stats) > 0:
            best_step = step_stats['win_rate'].idxmax()
            report.append(f" ðŸ’¡ ìµœì  íƒˆì¶œ êµ¬ê°„: {best_step}ë‹¨ê³„ (ë¬¼íƒ€ê¸° ì›ì¹™ì˜ ìŠ¹ë¦¬)")
    else:
        report.append("  (ë§¤ë„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„ ë¶ˆê°€)")

    # --- [ì„¹ì…˜ 2. ì‹œê·¸ë„ í•„í„°ë§ ì„±ê³¼ (Secondary)] ---
    report.append(f"\nðŸ“¡ [2. ì‹œê·¸ë„ í•„í„°ë§ ì„±ê³¼ (RSI ë“±)]")
    if not df_sig.empty:
        # JSON í˜•íƒœì˜ íŒ©í„°ë“¤ì„ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ í™•ìž¥
        factors_df = df_sig['factors_json'].apply(lambda x: pd.Series(json.loads(x)))
        df_sig = pd.concat([df_sig.drop('factors_json', axis=1), factors_df], axis=1)
        
        # RSI ë¶„ì„
        df_sig['rsi_bin'] = pd.cut(df_sig['rsi_1m'], bins=range(0, 105, 10))
        rsi_stats = df_sig.groupby('rsi_bin')['interval_5m_change'].agg(['count', 'mean']).rename(columns={'mean': 'avg_profit'})
        rsi_stats['win_rate'] = df_sig.groupby('rsi_bin')['interval_5m_change'].apply(lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0)
        
        report.append(f" âœ… ì‹œê·¸ë„ í‘œë³¸: {len(df_sig)}ê±´")
        # ìŠ¹ë¥ ì´ ë†’ì€ ìƒìœ„ 3ê°œ êµ¬ê°„ë§Œ ì¶œë ¥ (ìš”ì•½)
        top_rsi = rsi_stats.sort_values('win_rate', ascending=False).head(3)
        for idx, row in top_rsi.iterrows():
            if row['count'] > 0:
                report.append(f" â€¢ RSI {idx}: ìŠ¹ë¥  {row['win_rate']*100:4.1f}% | ì˜ˆìƒìˆ˜ìµ {row['avg_profit']:5.2f}%")
    else:
        report.append("  (ì‹œê·¸ë„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.)")

    # --- [ì„¹ì…˜ 3. ëŒ€ì›ì¹™ ê°€ì´ë“œ] ---
    report.append(f"\nðŸ’¡ [ì—”ì§„ ìµœì í™” ì œì–¸]")
    report.append(f" - 1:1:2:4:8 ìˆ˜ì—´ì— ë”°ë¥¸ ìžê¸ˆ ë°°ë¶„ì€ í˜„ìž¬ ìœ íš¨í•©ë‹ˆë‹¤.")
    report.append(f" - ìžê¸ˆ ë¶€ì¡± ì‹œ ì¢…ëª© ìˆ˜ë¥¼ ì¤„ì—¬ì„œë¼ë„ MAX ë‹¨ê³„ ë¬¼íƒ€ê¸°ë¥¼ ì‚¬ìˆ˜í•˜ì‹­ì‹œì˜¤.")
    
    return "\n".join(report)

_cache_data = None
_last_cache_time = 0

def update_cache():
    global _cache_data, _last_cache_time
    try:
        conn = sqlite3.connect(DB_FILE)
        query = '''
        SELECT s.factors_json, r.interval_5m_change
        FROM signal_snapshots s
        JOIN response_metrics r ON s.id = r.signal_id
        '''
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if not df.empty:
            def safe_json_load(x):
                try: return pd.Series(json.loads(x))
                except: return pd.Series()
            
            factors_df = df['factors_json'].apply(safe_json_load)
            _cache_data = pd.concat([df.drop('factors_json', axis=1), factors_df], axis=1)
            _last_cache_time = time.time()
            logger.info(f"ðŸ”„ [LASTTRADE Math] {len(_cache_data)}ê±´ì˜ ì‹œê·¸ë„ ìºì‹œ ê°±ì‹  ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ì§€ì‹ ë² ì´ìŠ¤ ê°±ì‹  ì‹¤íŒ¨: {e}")

def get_win_probability(rsi_1m, rsi_diff=None):
    """
    RSI ê¸°ë°˜ ì˜ˆìƒ ìŠ¹ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    (ì¶”í›„ WATER ë‹¨ê³„ ë°ì´í„°ì™€ ì—°ë™í•˜ì—¬ ë³´ì • ê°€ëŠ¥)
    """
    global _cache_data, _last_cache_time
    
    if _cache_data is None or (time.time() - _last_cache_time > 1800):
        update_cache()
    
    if _cache_data is None or _cache_data.empty:
        return 0.5, 0
        
    base_prob = 0.5
    total_count = 0
    
    try:
        # ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
        rsi_margin = 5
        rsi_group = _cache_data[(_cache_data.get('rsi_1m', 0) >= rsi_1m - rsi_margin) & (_cache_data.get('rsi_1m', 0) <= rsi_1m + rsi_margin)]
        
        if not rsi_group.empty:
            rsi_prob = (rsi_group['interval_5m_change'] > 0).sum() / len(rsi_group)
            total_count = len(rsi_group)
            base_prob = rsi_prob
                
    except Exception as e:
        logger.error(f"ìŠ¹ë¥  ê³„ì‚° ì˜¤ë¥˜: {e}")
        
    return base_prob, total_count

if __name__ == "__main__":
    analyze_signals()
