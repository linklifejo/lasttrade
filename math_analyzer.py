import sqlite3
import json
import pandas as pd
from database import DB_FILE
from logger import logger

def analyze_signals():
    """
    ê¸°ì¡´ ë¶„ì„ ë¡œì§ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    report = get_analysis_report()
    print(report)
    return report

def get_analysis_report():
    """
    ë¶„ì„ ì„±ê³¼ ìš”ì•½ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    conn = sqlite3.connect(DB_FILE)
    
    # 1. ë°ì´í„° ë¡œë“œ (ì‹œê·¸ë„ + ì„±ê³¼ì§€í‘œ)
    query = '''
    SELECT 
        s.id, s.timestamp, s.code, s.factors_json, 
        r.interval_1m_change, r.interval_5m_change, r.max_drawdown, r.max_profit
    FROM signal_snapshots s
    JOIN response_metrics r ON s.id = r.signal_id
    '''
    try:
        df = pd.read_sql_query(query, conn)
    except Exception as e:
        return f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}"
    finally:
        conn.close()
    
    if df.empty:
        return "âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‹œê·¸ë„ê³¼ ëŒ€ì‘ ë°ì´í„°ê°€ ìŒ“ì¼ ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
    
    # 2. JSON í˜•íƒœì˜ íŒ©í„°ë“¤ì„ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¥
    factors_df = df['factors_json'].apply(lambda x: pd.Series(json.loads(x)))
    df = pd.concat([df.drop('factors_json', axis=1), factors_df], axis=1)
    
    report = []
    report.append(f"ğŸ“Š [ìˆ˜í•™ì  ì—”ì§„ ë¶„ì„ ë¦¬í¬íŠ¸]")
    report.append(f"âœ… ë¶„ì„ ëŒ€ìƒ: {len(df)}ê±´\n")
    
    # 3. RSI_1m ê¸°ì¤€ êµ¬ê°„ë³„ ì„±ê³¼ ë¶„ì„
    df['rsi_bin'] = pd.cut(df['rsi_1m'], bins=range(0, 105, 5))
    
    performance = df.groupby('rsi_bin').agg({
        'id': 'count',
        'interval_1m_change': 'mean',
        'interval_5m_change': 'mean',
        'max_profit': 'mean',
        'max_drawdown': 'min'
    }).rename(columns={'id': 'count'})
    
    win_rate = df.groupby('rsi_bin')['interval_5m_change'].apply(lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0)
    performance['win_rate'] = win_rate
    
    report.append("[RSI 1m êµ¬ê°„ë³„ ì„±ê³¼]")
    perf_clean = performance.dropna()
    if not perf_clean.empty:
        for idx, row in perf_clean.iterrows():
            report.append(f"â€¢ {idx}: {int(row['count'])}ê±´ | ìŠ¹ë¥  {row['win_rate']*100:.1f}% | ìˆ˜ìµ {row['interval_5m_change']:.2f}%")
    else:
        report.append("(ë°ì´í„° ì—†ìŒ)")
    
    # 4. ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì²œ
    reliable = performance[performance['count'] >= 3] # ìµœì†Œ ê±´ìˆ˜ ì™„í™”
    if not reliable.empty:
        best_rsi_bin = reliable['interval_5m_change'].idxmax()
        best_stats = reliable.loc[best_rsi_bin]
        
        report.append(f"\nğŸ’¡ [ì¶”ì²œ íŒŒë¼ë¯¸í„°]")
        report.append(f" - ìµœì  RSI 1m êµ¬ê°„: {best_rsi_bin}")
        report.append(f" - ê¸°ëŒ€ ìˆ˜ìµë¥ (5m): {best_stats['interval_5m_change']:.2f}%")
        report.append(f" - í•´ë‹¹ êµ¬ê°„ ìŠ¹ë¥ : {best_stats['win_rate']*100:.1f}%")
    else:
        report.append("\nğŸ’¡ ìœ ì˜ë¯¸í•œ íŒ¨í„´ì„ ì°¾ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 3ê±´ í•„ìš”).")

    return "\n".join(report)

_cache_win_rates = None
_last_cache_time = 0

def get_win_probability(rsi_1m):
    """
    íŠ¹ì • RSI ê°’ì— ëŒ€í•œ (ê¸°ëŒ€ ìŠ¹ë¥ , í‘œë³¸ ìˆ˜)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ìºì‹œ ì‚¬ìš©)
    """
    global _cache_win_rates, _last_cache_time
    
    # 1ì‹œê°„ë§ˆë‹¤ ìºì‹œ ê°±ì‹ 
    if _cache_win_rates is None or (time.time() - _last_cache_time > 3600):
        update_cache()
    
    if _cache_win_rates is None or _cache_win_rates.empty:
        return 0.5, 0
        
    # í•´ë‹¹ RSIê°€ ì†í•œ êµ¬ê°„ ì°¾ê¸°
    for idx, row in _cache_win_rates.iterrows():
        if rsi_1m in idx:
            return float(row['win_rate']), int(row['count'])
            
    return 0.5, 0

def update_cache():
    global _cache_win_rates, _last_cache_time
    conn = sqlite3.connect(DB_FILE)
    query = '''
    SELECT s.factors_json, r.interval_5m_change
    FROM signal_snapshots s
    JOIN response_metrics r ON s.id = r.signal_id
    '''
    try:
        df = pd.read_sql_query(query, conn)
        if df.empty: return
        
        factors_df = df['factors_json'].apply(lambda x: pd.Series(json.loads(x)))
        df = pd.concat([df.drop('factors_json', axis=1), factors_df], axis=1)
        
        df['rsi_bin'] = pd.cut(df['rsi_1m'], bins=range(0, 105, 5))
        _cache_win_rates = df.groupby('rsi_bin')['interval_5m_change'].apply(
            lambda x: pd.Series({'win_rate': (x > 0).sum() / len(x), 'count': len(x)})
        ).unstack()
        _last_cache_time = time.time()
        logger.info(f"ğŸ”„ [Math Cache] ìŠ¹ë¥  ìºì‹œ ê°±ì‹  ì™„ë£Œ ({len(df)}ê±´ ê¸°ë°˜)")
    except Exception as e:
        logger.error(f"ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    analyze_signals()
